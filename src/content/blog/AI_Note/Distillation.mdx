---
title: "Knowledge Distillation (KD) Crash Course Notes"
description: "Notes on Knowledge Distillation Methods and Techniques"
image: "../cover/cover_10.png"
publishDate: "2025-12-02"
tags: ["Scientific Research","Fa-De-Re","Knowledge Distillation"]
---

## Algorithm Principles & Overview

实际终端算力有限 + 预训练大模型（参数规模每年增加 10 倍） → 需要模型压缩 + 加速推理 → 知识蒸馏（Knowledge Distillation, KD）

![Basic Framework for Knowledge Distillation](../pic/1.png)

### 知识的表示与迁移







